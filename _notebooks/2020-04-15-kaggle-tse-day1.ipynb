{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Tweet Sentiment Extraction\n",
    "> My journey to learn some NLP.\n",
    "\n",
    "- toc: true \n",
    "- badges: false\n",
    "- comments: true\n",
    "- categories: [kaggle, nlp]\n",
    "- image: images/kaggle_tse/twitter.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "Here lies my notes about my solution for the [Kaggle Twitter Sentiment Extraction competition](https://www.kaggle.com/c/tweet-sentiment-extraction).\n",
    "\n",
    "First of all, I am still a novice in the field of natural language processing. \n",
    "This means that all of these NLP concepts, and even Deep Learning approaches to this fields, are challenging for me to understand and apply. \n",
    "Hence, if my approaches somehow become wrong, please give me a notification via my personal email: [huygdng@gmail.com](huygdng@gmail.com).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this competition\n",
    "\n",
    "Now let's go to the competition's description. We know that, Sentiment classification is a well-known problem in NLP. \n",
    "Given a sentence (a tweet, a line from one book, etc.), our algorithm should be able to tell the \"attitude\" of that input. \n",
    "For example, given a sentence like this:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Kaggle is fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above sentence is full of \"positive\" thought, and if I have a proper sentiment classifier, I will expect it to\n",
    "return \"positive\" as the \"attitude\" of that sentence as well.\n",
    "\n",
    "Now, back to the competition. The challenge in this competition is not to classify the sentiment of tweets, but to **pick out** parts that reflect the sentiment of those tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is from the original description of the competition:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Capturing sentiment in language is important in these times where decisions and reactions are created and updated in seconds.\n",
    "But, which words actually lead to the sentiment description?\n",
    "In this competition you will need to pick out the part of the tweet (word or phrase) that reflects the sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the above positive example, it is expected from a proper sentiment extraction model to point out the term 'fun!' as the cause of the sentence's positiveness. We can observe that, in this example, not only the word 'fun' is marked as the positive term, but its corresponding punctuation as well. This phenomenon affects the choice of approaches, as we will see later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first glance at data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some samples from the training dataset:\n",
    "\n",
    "![kaggle-sample](../images/kaggle_tse/kaggle_sample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the training data does give us a lot information:\n",
    "\n",
    "- The information that we could use for our training includes 'text' and 'sentiment'.\n",
    "\n",
    "- The predicion we would make, is the 'selected_text' column.\n",
    "\n",
    "- We have 3 classes for sentiment: positive, negative and neutral.\n",
    "\n",
    "- About 'text' column: The format is quite ...diverge. There are incomplete sentences ('is back home ... '), sentences with some emoticon ('... <3 <3'), sentences with some typos ('Hes just not ...'), and more.\n",
    "\n",
    "- The sentiment distribution is quite good: neutral 40%, positive 31% and negative 28%.\n",
    "\n",
    "- The selected text contains both the word, punctuation and also some emoticon as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listed below are some more basic analysis on this data. We first observe that, the sentiment distribution of training dataset and test dataset are equivalent.\n",
    "\n",
    "![kaggle-eda1](../images/kaggle_tse/sentiment_dist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our task in this competition, once again, is to find correct pieces of text that emphasize the sentiment of the tweet. Hence, observing the distribution of word counts in both the original tweet the selected tweet (the target) in each sentiment class is a good idea.\n",
    "\n",
    "![kaggle-eda2](../images/kaggle_tse/text_length_comparison1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also the corresponding histogram of word counts.\n",
    "\n",
    "![kaggle-eda1](../images/kaggle_tse/text_length_comparison2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the 3 sentiment classes, the 'neutral' class has one interesting characteristics: The length of input tweet and target piece of text are almost the same. Hence, we can make use of it, as a simple heuristic post-process rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem can be treated as **Token classification** problem (i.e., Name Entity Recognition, Part-of-Speech, ...) , or **Question-answering** problem.\n",
    "\n",
    "However, when working with this problem as the token classification problem, we do not include punctuations as part of the model's results. Moreover, modifying token with punctuations is not a good idea - not only does that approach expand the vocabulary (which goes along with time and computational resources to learn the language model), but it also does not guarantee that we can learn the similarity between word and word with tokens. Hence, this approach is not optimal.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Question-answering problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I formulated this task as question answering problem: given a question and a context, it is expected that the model should find acceptable  the \n",
    "given a question and a context, we train a transformer model to find the answer in the text column (the context)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now, I have tried some model architectures:\n",
    "    \n",
    "   - The pre-trained BERT[[1](https://arxiv.org/abs/1810.04805)] with custom header. \n",
    "   \n",
    "   - The pre-trained Electra[[2](https://arxiv.org/abs/2003.10555)] with custom header.\n",
    "   \n",
    "   - The pre-trained RoBERTa[[3](https://arxiv.org/abs/1907.11692)] with custom header\n",
    "      \n",
    "The custom header includes 2 Linear layers, with ReLU and Dropout for the first linear layer. The header's weights are initialized using Kaiming He normal initialization [[4](https://arxiv.org/abs/1502.01852)]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Devlin, J., Chang, M.W., Lee, K. and Toutanova, K., 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. *arXiv preprint arXiv:1810.04805*.\n",
    "\n",
    "[2] Clark, K., Luong, M.T., Le, Q.V. and Manning, C.D., 2020. Electra: Pre-training text encoders as discriminators rather than generators. *arXiv preprint arXiv:2003.10555*.\n",
    "\n",
    "[3] Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L. and Stoyanov, V., 2019. Roberta: A robustly optimized bert pretraining approach. *arXiv preprint arXiv:1907.11692*.\n",
    "\n",
    "[4] He, K., Zhang, X., Ren, S. and Sun, J., 2015. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. *In Proceedings of the IEEE international conference on computer vision* (pp. 1026-1034)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
